{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  Counter({'b': 4490, 'e': 4237, 't': 1211, 'm': 734})\n",
      "valid:  Counter({'b': 589, 'e': 520, 't': 137, 'm': 88})\n",
      "test:  Counter({'b': 548, 'e': 522, 't': 176, 'm': 88})\n"
     ]
    }
   ],
   "source": [
    "'''50. データの入手・整形\n",
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
    "情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
    "抽出された事例をランダムに並び替える．\n",
    "抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
    "学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．'''\n",
    "\n",
    "# !pip install sklearn\n",
    "# FORMAT: ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "path = 'data/ch6/NewsAggregatorDataset/'\n",
    "\n",
    "df = pd.read_csv(path + 'newsCorpora.csv', sep='\\t', header=None)\n",
    "df.columns = ['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP']\n",
    "\n",
    "newsdataset = df.loc[df['PUBLISHER'].isin(['Reuters','Huffington Post','Businessweek','Contactmusic.com','Daily Mail'])]\n",
    "newsdataset = newsdataset.sample(frac=1).reset_index(drop=True)   #shuffle all data and reset index\n",
    "X = newsdataset[['TITLE','CATEGORY']]\n",
    "\n",
    "train, valid_test = train_test_split(X, test_size=0.2)\n",
    "valid, test = train_test_split(valid_test, test_size=0.5)\n",
    "\n",
    "train.to_csv(path + 'train.txt', sep='\\t', index=False, header=None)\n",
    "valid.to_csv(path + 'valid.txt', sep='\\t', index=False, header=None)\n",
    "test.to_csv(path + 'test.txt', sep='\\t', index=False, header=None)\n",
    "\n",
    "print(\"train: \",Counter(train['CATEGORY']))\n",
    "print(\"valid: \",Counter(valid['CATEGORY']))\n",
    "print(\"test: \",Counter(test['CATEGORY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''51. 特徴量抽出\n",
    "学習データ，検証データ，評価データから特徴量を抽出し，\n",
    "それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ．\n",
    "なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．\n",
    "記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう．'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "train = pd.read_csv(path +'train.txt', sep='\\t', header=None ,names=['TITLE', 'CATEGORY'])\n",
    "valid = pd.read_csv(path +'valid.txt', sep='\\t', header=None ,names=['TITLE', 'CATEGORY'])\n",
    "test  = pd.read_csv(path +'test.txt', sep='\\t', header=None ,names=['TITLE', 'CATEGORY'])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train['TITLE'])\n",
    "X_valid = vectorizer.transform(valid['TITLE'])\n",
    "X_test = vectorizer.transform(test['TITLE'])\n",
    "\n",
    "pd.DataFrame(X_train.toarray()).to_csv(path +'train_feature.txt', sep='\\t', index=False, header=None)\n",
    "pd.DataFrame(X_valid.toarray()).to_csv(path +'valid_feature.txt', sep='\\t', index=False, header=None)\n",
    "pd.DataFrame(X_test.toarray()).to_csv(path  +'test_feature.txt', sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=3000)\n"
     ]
    }
   ],
   "source": [
    "'''52. 学習\n",
    "51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = pd.read_csv(path + 'train_feature.txt',sep='\\t', header=None)\n",
    "y_train = pd.read_csv(path + 'train.txt',sep='\\t', header=None)[1]\n",
    "\n",
    "clf = LogisticRegression(max_iter=3000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 't' ... 't' 'b' 'e']\n",
      "train acc:  1.0\n",
      "test acc:  0.9055472263868066\n",
      "\n",
      "training dataset confusion matrix\n",
      "[[4502    0    0    0]\n",
      " [   0 4241    0    0]\n",
      " [   0    0  728    0]\n",
      " [   0    0    0 1201]]\n",
      "\n",
      "testing dataset confusion matrix\n",
      "[[514  18   3  13]\n",
      " [  7 511   1   3]\n",
      " [ 12  12  63   1]\n",
      " [ 33  21   2 120]]\n",
      "\n",
      "Micro\n",
      "precision score: 0.9055472263868066\n",
      "recall score: 0.9055472263868066\n",
      "f1 score: 0.9055472263868066\n",
      "\n",
      "Macro\n",
      "precision score: 0.9015839411349262\n",
      "recall score: 0.8286526700429921\n",
      "f1 score: 0.8587315199542672\n",
      "\n",
      "None\n",
      "precision score: [0.90812721 0.90925267 0.91304348 0.87591241]\n",
      "recall score: [0.9379562  0.9789272  0.71590909 0.68181818]\n",
      "f1 score: [0.92280072 0.94280443 0.80254777 0.76677316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''53. 予測\n",
    "52で学習したロジスティック回帰モデルを用い，\n",
    "与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．\n",
    "'''\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(y_train_pred)\n",
    "\n",
    "\n",
    "'''54. 正解率の計測\n",
    "52で学習したロジスティック回帰モデルの正解率を，\n",
    "学習データおよび評価データ上で計測せよ．'''\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_valid = pd.read_csv(path + 'valid_feature.txt',sep='\\t', header=None)\n",
    "y_valid = pd.read_csv(path + 'valid.txt',sep='\\t', header=None)[1]\n",
    "\n",
    "X_test = pd.read_csv(path + 'test_feature.txt',sep='\\t', header=None)\n",
    "y_test = pd.read_csv(path + 'test.txt',sep='\\t', header=None)[1]\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print('train acc: ',accuracy_score(y_train, y_train_pred))\n",
    "print('test acc: ', accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "\n",
    "'''55. 混同行列の作成\n",
    "52で学習したロジスティック回帰モデルの混同行列（confusion matrix）を，学習データおよび評価データ上で作成せよ．'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print('\\ntraining dataset confusion matrix')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print('\\ntesting dataset confusion matrix')\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "\n",
    "'''56. 適合率，再現率，F1スコアの計測\n",
    "52で学習したロジスティック回帰モデルの適合率，再現率，F1スコアを，評価データ上で計測せよ．\n",
    "カテゴリごとに適合率，再現率，F1スコアを求め，\n",
    "カテゴリごとの性能をマイクロ平均（micro-average）とマクロ平均（macro-average）で統合せよ．'''\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision,recall,f1,_ = precision_recall_fscore_support(y_test, y_test_pred, average='micro')\n",
    "print('\\nMicro\\nprecision score: {}\\nrecall score: {}\\nf1 score: {}\\n'.format(precision,recall,f1))\n",
    "precision,recall,f1,_ = precision_recall_fscore_support(y_test, y_test_pred, average='macro')\n",
    "print('Macro\\nprecision score: {}\\nrecall score: {}\\nf1 score: {}\\n'.format(precision,recall,f1))\n",
    "precision,recall,f1,_ = precision_recall_fscore_support(y_test, y_test_pred, average=None)\n",
    "print('None\\nprecision score: {}\\nrecall score: {}\\nf1 score: {}\\n'.format(precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n",
      "top features:\n",
      " [('bank', 1.938062778303614), ('fed', 1.7641833555723037), ('ecb', 1.6499986914740037), ('obamacare', 1.6047951284878035), ('yellen', 1.5840908736792165), ('ukraine', 1.490314559261935), ('euro', 1.4818975362647135), ('china', 1.4609736231452768), ('pfizer', 1.4561007964230088), ('argentina', 1.4506487417518776)]\n",
      "bottom features:\n",
      " [('activision', -1.3641356109443692), ('aereo', -1.2829854681223472), ('cap', -1.2390198775382195), ('ebola', -1.1539809148327385), ('she', -1.083694484459867), ('heartbleed', -1.038659360991059), ('sony', -0.9536628222444056), ('fcc', -0.9530970166497248), ('gay', -0.9117944062765752), ('subscription', -0.911644760589598)]\n",
      "--------------------------------------------------------------------------------\n",
      "entertainment\n",
      "top features:\n",
      " [('chris', 1.6529140788144248), ('kardashian', 1.6315118546066742), ('paul', 1.6121329799920774), ('thrones', 1.3632989160896418), ('transformers', 1.3589957059520246), ('movie', 1.3156606362180596), ('miley', 1.3083860350474763), ('jay', 1.2823155579256333), ('film', 1.2726463329632696), ('beyonce', 1.2696464204992255)]\n",
      "bottom features:\n",
      " [('google', -1.6015526262657165), ('gm', -1.2875207394568753), ('facebook', -1.2547366581728652), ('microsoft', -1.236095288641563), ('ceo', -1.129709948669559), ('data', -1.1183831979781242), ('china', -1.100394837799071), ('risk', -1.0816142438130698), ('ebola', -1.0631972959817337), ('climate', -1.0543652068246872)]\n",
      "--------------------------------------------------------------------------------\n",
      "health\n",
      "top features:\n",
      " [('ebola', 2.715229292604341), ('fda', 2.1603479752107675), ('cancer', 2.157018360247166), ('drug', 1.887999361720546), ('mers', 1.8116530665619979), ('cases', 1.800820842032243), ('study', 1.5466604227272298), ('cigarettes', 1.514515047774281), ('brain', 1.4748913663372003), ('cdc', 1.4533790473081003)]\n",
      "bottom features:\n",
      " [('facebook', -0.8403749919588054), ('gm', -0.8213759428322633), ('dimon', -0.789789109126338), ('apple', -0.7471205542472803), ('climate', -0.724019056878846), ('twitter', -0.6936467581527221), ('buy', -0.656488594173278), ('price', -0.5821725021013401), ('amazon', -0.5510847357679268), ('game', -0.5378887774621077)]\n",
      "--------------------------------------------------------------------------------\n",
      "science and technology\n",
      "top features:\n",
      " [('facebook', 2.693139095148873), ('google', 2.660846839495678), ('microsoft', 2.427659918887116), ('apple', 2.3906304248575156), ('climate', 2.279279167691832), ('tesla', 1.981158600816763), ('heartbleed', 1.9595268492756548), ('nasa', 1.8312299193035286), ('fcc', 1.7977149501183523), ('gm', 1.6555555201005225)]\n",
      "bottom features:\n",
      " [('stocks', -1.165310989475191), ('percent', -0.9060054077041297), ('shares', -0.8193769483714751), ('thrones', -0.7721506704124104), ('valued', -0.7683965899815788), ('should', -0.7489517596204757), ('fed', -0.7441321445923588), ('american', -0.7429629019191649), ('drug', -0.7155864584855733), ('his', -0.7070140281098548)]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''57. 特徴量の重みの確認\n",
    "52で学習したロジスティック回帰モデルの中で，重みの高い特徴量トップ10と，重みの低い特徴量トップ10を確認せよ．'''\n",
    "# resources form stackoverflow\n",
    "# https://stackoverflow.com/questions/28667594/linking-sklearn-logisticregression-coefficients-to-terms-in-a-sparse-matrix-and\n",
    "  \n",
    "labels = ['business','entertainment','health','science and technology']\n",
    "  \n",
    "for c in zip(labels,clf.coef_):\n",
    "    print(c[0])\n",
    "    top_features = sorted(list(zip(vectorizer.get_feature_names(), c[1])),key=lambda x: (x[1]),reverse=True)[:10]\n",
    "    print(\"top features:\\n\",top_features)\n",
    "    bottom_features = sorted(list(zip(vectorizer.get_feature_names(), c[1])),key=lambda x: (x[1]),reverse=False)[:10]\n",
    "    print(\"bottom features:\\n\",bottom_features)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''58. 正則化パラメータの変更\n",
    "ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，\n",
    "学習時の過学習（overfitting）の度合いを制御できる．\n",
    "異なる正則化パラメータでロジスティック回帰モデルを学習し，\n",
    "学習データ，検証データ，および評価データ上の正解率を求めよ．\n",
    "実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_valid = pd.read_csv(path+ 'valid_feature.txt',sep='\\t', header=None)\n",
    "y_valid = pd.read_csv(path+ 'valid.txt',sep='\\t', header=None)[1]\n",
    "\n",
    "c_parameters = [0.1,1,10,100]\n",
    "trn_acc, val_acc, tst_acc = [],[],[]\n",
    "\n",
    "for c in c_parameters:\n",
    "    clf = LogisticRegression(C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_valid_pred = clf.predict(X_valid)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    trn_acc.append(accuracy_score(y_train, y_train_pred))\n",
    "    val_acc.append(accuracy_score(y_valid, y_valid_pred))\n",
    "    tst_acc.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "plt.plot(c_parameters, trn_acc, label='train acc')\n",
    "plt.plot(c_parameters, val_acc, label='valid acc')\n",
    "plt.plot(c_parameters, tst_acc,  label='test acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8738963538991698\n",
      "Best Params:  {'C': 0.1, 'solver': 'lbfgs'}\n",
      "test acc:  0.8733133433283359\n"
     ]
    }
   ],
   "source": [
    "'''59. ハイパーパラメータの探索\n",
    "学習アルゴリズムや学習パラメータを変えながら，カテゴリ分類モデルを学習せよ．\n",
    "検証データ上の正解率が最も高くなる学習アルゴリズム・パラメータを求めよ．\n",
    "また，その学習アルゴリズム・パラメータを用いたときの評価データ上の正解率を求めよ．\n",
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_trn = pd.concat([X_train,X_valid],axis=0)\n",
    "y_trn =  pd.concat([y_train,y_valid],axis=0)\n",
    "\n",
    "c_params = [0.01, 0.1, 1, 10]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "\n",
    "param_grid = dict(C=c_params, solver = sol)\n",
    "\n",
    "clf = LogisticRegression(dual = False, max_iter=3000)\n",
    "# decide params by cross-validation default: 5 fold\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_trn, y_trn)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "\n",
    "y_test_pred = grid.predict(X_test)\n",
    "print('test acc: ', accuracy_score(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
